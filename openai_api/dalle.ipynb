{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ce6f92-09b4-42b6-a6f1-2e8b1f33aec7",
   "metadata": {},
   "source": [
    "## 快速入门 文生图模型 DALL·E\n",
    "\n",
    "OpenAI **Images API** 提供了三种与图像交互的方法：\n",
    "\n",
    "1. 基于文本提示生成图像（DALL·E 3 和 DALL·E 2）\n",
    "2. 通过模型编辑（替换）已存在图像的某些区域，根据新的文本提示创建编辑过的图像版本（仅限 DALL·E 2）\n",
    "3. 创建现有图像的变体（仅限 DALL·E 2）\n",
    "\n",
    "本指南主要介绍第一种文生图像的使用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966211c-9683-4119-ad75-5966d96bdc37",
   "metadata": {},
   "source": [
    "## 使用 DALL·E 3 生成图像\n",
    "\n",
    "**关于 `DALL·E 3` 模型更新的更多内容，请参考 [OpenAI Cookbook](https://cookbook.openai.com/articles/what_is_new_with_dalle_3)**\n",
    "\n",
    "\n",
    "### 图像生成 API\n",
    "\n",
    "新参数：\n",
    "- model（'dall-e-2' 或 'dall-e-3'）：您正在使用的模型。请注意将其设置为 'dall-e-3'，因为如果为空，默认为 'dall-e-2'。\n",
    "- style（'natural' 或 'vivid'）：生成图像的风格。必须是 'vivid' 或 'natural' 之一。'vivid' 会使模型倾向于生成超现实和戏剧性的图像。'natural' 会使模型产生更自然、不那么超现实的图像。默认为 'vivid'。\n",
    "- quality（'standard' 或 'hd'）：将生成的图像质量。'hd' 创建细节更精细、整体一致性更高的图像。默认为 'standard'。\n",
    "\n",
    "其他参数：\n",
    "- prompt（str）：所需图像的文本描述。最大长度为1000个字符。必填字段。\n",
    "- n（int）：要生成的图像数量。必须在1到10之间。默认为1。对于 dall-e-3，只支持 n=1。\n",
    "- size（...）：生成图像的尺寸。对于 DALL·E-2 模型，必须是 256x256、512x512 或 1024x1024 之一。对于 DALL·E-3 模型，必须是 1024x1024、1792x1024 或 1024x1792 之一。\n",
    "- response_format（'url' 或 'b64_json'）：返回生成图像的格式。必须是 \"url\" 或 \"b64_json\" 之一。默认为 \"url\"。\n",
    "- user（str）：代表您的终端用户的唯一标识符，将帮助 OpenAI 监控和检测滥用。了解更多。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "394827cc-6824-460d-a4c7-8d0f821ccf41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T10:36:49.771203Z",
     "start_time": "2025-10-18T10:36:46.603984Z"
    }
   },
   "source": [
    "import azure_openai\n",
    "client = azure_openai.client\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"a white siamese cat\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url"
   ],
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotFoundError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mazure_openai\u001B[39;00m\n\u001B[32m      2\u001B[39m client = azure_openai.client\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m response = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdall-e-3\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43ma white siamese cat\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43msize\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m1024x1024\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquality\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstandard\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m image_url = response.data[\u001B[32m0\u001B[39m].url\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Workspace\\AILearning\\AgentLearning\\openai-quickstart\\.venv\\Lib\\site-packages\\openai\\resources\\images.py:264\u001B[39m, in \u001B[36mImages.generate\u001B[39m\u001B[34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    205\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate\u001B[39m(\n\u001B[32m    206\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    207\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m    221\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m    222\u001B[39m ) -> ImagesResponse:\n\u001B[32m    223\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    224\u001B[39m \u001B[33;03m    Creates an image given a prompt.\u001B[39;00m\n\u001B[32m    225\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    262\u001B[39m \u001B[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[32m    263\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m264\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    265\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/images/generations\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    266\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    267\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    268\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mquality\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquality\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msize\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstyle\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    275\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    276\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    277\u001B[39m \u001B[43m            \u001B[49m\u001B[43mimage_generate_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mImageGenerateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    282\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mImagesResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Workspace\\AILearning\\AgentLearning\\openai-quickstart\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1283\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1269\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1270\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1271\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1278\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1279\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1280\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1281\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1282\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1283\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Workspace\\AILearning\\AgentLearning\\openai-quickstart\\.venv\\Lib\\site-packages\\openai\\_base_client.py:960\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[39m\n\u001B[32m    957\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    958\u001B[39m     retries_taken = \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m960\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    961\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    962\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    963\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    964\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    965\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    966\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Workspace\\AILearning\\AgentLearning\\openai-quickstart\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1064\u001B[39m, in \u001B[36mSyncAPIClient._request\u001B[39m\u001B[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[39m\n\u001B[32m   1061\u001B[39m         err.response.read()\n\u001B[32m   1063\u001B[39m     log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1066\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._process_response(\n\u001B[32m   1067\u001B[39m     cast_to=cast_to,\n\u001B[32m   1068\u001B[39m     options=options,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1072\u001B[39m     retries_taken=retries_taken,\n\u001B[32m   1073\u001B[39m )\n",
      "\u001B[31mNotFoundError\u001B[39m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbf4f70-68ab-445e-b83e-797cc7a2e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-2sFP0xzqD8S7a8Nl0TVYoVF5/user-fhTAqEGBJ62fdTxxDM54d1v0/img-1VzjEFD7Z5WOeew0zUc5aiPU.png?st=2024-04-23T12%3A30%3A28Z&se=2024-04-23T14%3A30%3A28Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-23T01%3A12%3A46Z&ske=2024-04-24T01%3A12%3A46Z&sks=b&skv=2021-08-06&sig=J2CDkSjl2odQgJnjBdkdla9KBmXYGSSHbFFx/Tuw%2Brc%3D\n"
     ]
    }
   ],
   "source": [
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702cc01b-cd92-4549-8e82-059e9d8edaf2",
   "metadata": {},
   "source": [
    "### 高清模式（quality=\"hd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfaeb3ae-0a6f-4532-9990-da6a6f6ab919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-2sFP0xzqD8S7a8Nl0TVYoVF5/user-fhTAqEGBJ62fdTxxDM54d1v0/img-RsAcOMmtjpDeO11oc4q0ESVP.png?st=2024-04-23T12%3A31%3A59Z&se=2024-04-23T14%3A31%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-22T23%3A04%3A49Z&ske=2024-04-23T23%3A04%3A49Z&sks=b&skv=2021-08-06&sig=7v6CtZRTgudE3eaIqNPBfUy%2B2suifnLqGWn8jtAquR0%3D\n"
     ]
    }
   ],
   "source": [
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"a white siamese cat\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"hd\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "print(response.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3cdee-8dd8-430c-990e-4c1db0116827",
   "metadata": {},
   "source": [
    "### 自然风格(style=\"natural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a970cc6-2e10-4e98-aaae-ddc313e4178b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-2sFP0xzqD8S7a8Nl0TVYoVF5/user-fhTAqEGBJ62fdTxxDM54d1v0/img-JmbmM55EL02zaz2OatEKGzbf.png?st=2024-04-23T12%3A32%3A23Z&se=2024-04-23T14%3A32%3A23Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-22T23%3A23%3A02Z&ske=2024-04-23T23%3A23%3A02Z&sks=b&skv=2021-08-06&sig=a6Pr6he%2BfAPAK4GidPeDy6xBNvVPHBJmVVQseYr0crY%3D\n"
     ]
    }
   ],
   "source": [
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"a white siamese cat\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "    style=\"natural\"\n",
    ")\n",
    "print(response.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171e20f-0f28-4605-a7ac-3e84a7a66414",
   "metadata": {},
   "source": [
    "### 戏剧风格(style=\"vivid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde0752b-08c4-4f68-8e23-dbd536a72de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-2sFP0xzqD8S7a8Nl0TVYoVF5/user-fhTAqEGBJ62fdTxxDM54d1v0/img-IjRfuBqKOmXXMX3t7PliMDLK.png?st=2024-04-23T12%3A32%3A41Z&se=2024-04-23T14%3A32%3A41Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-23T07%3A58%3A50Z&ske=2024-04-24T07%3A58%3A50Z&sks=b&skv=2021-08-06&sig=j/oCGxxtFx01Cpxoe2j3Mjy/7nromvCliTxobrURjr4%3D\n"
     ]
    }
   ],
   "source": [
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"a white siamese cat\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "    style=\"vivid\"\n",
    ")\n",
    "print(response.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eaa2a8-6466-43d0-818c-ac8cc34979f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
